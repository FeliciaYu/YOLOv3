# 一、YOLOv3算法特点

## 1.使用的主干特征提取网络为Darknet53

该主干特征提取网络具有两个特点：

1.使用了残差网络（Residual）

2.每一个卷积部分使用了特有的DarknetConv2D结构。每一次卷积的时候进行l2正则化，完成卷积后进行BatchNormalization标准化与LeakyReLU。普通的ReLU是将所有的负值都设为零，Leaky ReLU则是给所有负值赋予一个非零斜率。以数学的方式我们可以表示为：

![image-20230316200028051](C:\Users\31848\AppData\Roaming\Typora\typora-user-images\image-20230316200028051.png)

## 二、具体操作步骤

工作原理：

![image-20230316202935787](C:\Users\31848\AppData\Roaming\Typora\typora-user-images\image-20230316202935787.png)

![image-20230316202957666](C:\Users\31848\AppData\Roaming\Typora\typora-user-images\image-20230316202957666.png)

总体结构：

![image-20230316203803681](C:\Users\31848\AppData\Roaming\Typora\typora-user-images\image-20230316203803681.png)

![image-20230322200710260](C:\Users\31848\AppData\Roaming\Typora\typora-user-images\image-20230322200710260.png)

darknet网络之后：

![image-20230322195407042](C:\Users\31848\AppData\Roaming\Typora\typora-user-images\image-20230322195407042.png)



输入—>识别—>辨认—>返回结果—>输出

### 1.输入

输入是一个416x416x3；

进行下采样，宽高不断被压缩，通道数不断扩张；

获取的层被称为特征层，表示输入进来图片的特征；

会将Darknet-53倒数三个的shape值传入到右边箭头所指处；



### 2.识别

以最后一个为例子：

进行下一个步骤后会进行五次卷积操作；

然后根据情况有两个方向：

#### 1.右边方向

右边方向是进行分类预测和回归预测；

注：理解分类预测和回归预测

进行了两次卷积后，获得该层shape值

对shape值进行分解：

![image-20230316204841620](C:\Users\31848\AppData\Roaming\Typora\typora-user-images\image-20230316204841620.png)

获得的分类预测和回归预测的结果，是将输入进来的图片划分成13x13的网格，每一个网格上面存在着三个先验框，先验框是预先标注在图片上的。预测结果会判断先验框内部是否真实地包含物体，如果真实地包含物体，则会判断这个物体的种类。还会对先验框进行一个中心和宽高的调整，把它调整到正确的位置上。

当判断一个先验框内部是包含目标物体时，就可以找到它对应的预测框位置，就可以绘制框。

将25分解成20+1+4的原因：

1.20是因为这幅图所使用的数据集是voc的数据集，该数据集一共分20个类，而此处20是这20个类所对应的置信度，也就是这个框内的物体是属于这20个类中的哪一类。事实上代表的是一个属于某个类的概率。

2.1则是表示这个先验框内部是否有物体。

3.4则代表先验框的调整参数，因为需要四个参数才能确定一个框。

#### 2.上面方向

1.对五次卷积后的结果进行一个卷积后再进行上采样，上采样的结果会和在右边获得的26x26x512的特征层进行堆叠，事实上是构建特征金字塔的过程。

利用特征金字塔可以进行多尺度特征融合，提取出更有效地特征。

进行堆叠后还会进行五次卷积。

后面根据上图走向都是同理。

### 3.残差网络

残差图：

![image-20230317204326402](C:\Users\31848\AppData\Roaming\Typora\typora-user-images\image-20230317204326402.png)

1.分成一块一块（block），每个block既可以有输入也可以有输出。

2.对输入进行两部分处理，一部分会接受正常的卷积、激活函数、标准化等。另一部分会没有经过任何处理直接和尾部进行相连，即残差边。

3.然后会对这两部分进行相加，之后会获得残差网络块结构。

4.作用：使神经网络更容易优化与训练。

5.注意：在堆叠残差块时可以进行下采样。

### 4.训练部分

#### 1、计算loss所需参数

在计算loss的时候，实际上是pred和target之间的对比：
pred就是网络的预测结果。
target就是网络的真实框情况。

#### 2、pred是什么

对于yolo3的模型来说，网络最后输出的内容就是三个特征层每个网格点对应的预测框及其种类，即三个特征层分别对应着图片被分为不同size的网格后，每个网格点上三个先验框对应的位置、置信度及其种类。

输出层的shape分别为(13,13,75)，(26,26,75)，(52,52,75)，最后一个维度为75是因为是基于voc数据集的，它的类为20种，yolo3只有针对每一个特征层存在3个先验框，所以最后维度为3x25；
如果使用的是coco训练集，类则为80种，最后的维度应该为255 = 3x85，三个特征层的shape为(13,13,255)，(26,26,255)，(52,52,255)

现在的y_pre还是没有解码的，解码了之后才是真实图像上的情况。

#### 3、target是什么。

target就是一个真实图像中，真实框的情况。
第一个维度是batch_size，第二个维度是每一张图片里面真实框的数量，第三个维度内部是真实框的信息，包括位置以及种类。

#### 4、loss的计算过程

拿到pred和target后，不可以简单的减一下作为对比，需要进行如下步骤。

判断真实框在图片中的位置，判断其属于哪一个网格点去检测。判断真实框和这个特征点的哪个先验框重合程度最高。计算该网格点应该有怎么样的预测结果才能获得真实框，与真实框重合度最高的先验框被用于作为正样本。
根据网络的预测结果获得预测框，计算预测框和所有真实框的重合程度，如果重合程度大于一定门限，则将该预测框对应的先验框忽略。其余作为负样本。
最终损失由三个部分组成：a、正样本，编码后的长宽与xy轴偏移量与预测值的差距。b、正样本，预测结果中置信度的值与1对比；负样本，预测结果中置信度的值与0对比。c、实际存在的框，种类预测结果与实际结果的对比。

## 三.知识点理解

### 1.YOLO算法中anchors的理解

1.anchors是训练之前人为设定的先验框，网络输出结果的框就是在anchors的基础上进行调整的。先验框设定的好坏对于模型输出效果影响较大。

2.先验框的个数与图片是哪个物体的个数有关系，一个物体默认会设定9个先验框。

3.先验框在YOLO网络里，一张图片进入模型编码之后会输出三个特征层。anchors是在特征层上进行调整的，但最开始的anchors是相对于原图的，我们需要将anchors的大小以及物体的中心也对应到feature map上。我们可以从feature map（特征层）上获取到物体中心以及框的宽高的偏移量offset_x, offset_y, offset_w, offset_h, 然后根据偏移量对先验框进行调整。

### 2.

![image-20230405145659728](C:\Users\31848\AppData\Roaming\Typora\typora-user-images\image-20230405145659728.png)

此处的

(t>=t_min).float()返回的是布尔值

### 3.clip_by_tensor操作

1.作用

使数据在min到max之间，小于min的变为min，大于max的变为max
